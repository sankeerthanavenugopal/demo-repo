{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import os\n",
    "import re\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "#import sys\n",
    "#import numpy.matlib\n",
    "import scipy.io\n",
    "from scipy.signal import medfilt\n",
    "import librosa\n",
    "import os\n",
    "from os.path import exists\n",
    "## Vocoder function definition #########################################################################################\n",
    "# from typical_FA_contextfeats import contextFeats\n",
    "# from myfunctions import spectral_selection,  temporal_corr#,temp_vec_corr\n",
    "# from myfunctions import spectral_corr,statFunctions_Syl,statFunctions_Vwl,smooth,get_labels,vocoder_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import struct\n",
    "import math\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxilliary functions for feature computation\n",
    "def spectral_selection(x, n):                              #out of the 19 subband energies computed, this function selects the n energies with the highest values\n",
    "    y = x.shape\n",
    "    row = y[0]\n",
    "    col = y[1]\n",
    "    xx = []\n",
    "    for i in range(0,col,1):\n",
    "        v = x[:,i]                                           # his line selects the i-th column of x and assigns it to the variable v\n",
    "        v = np.array([v])\n",
    "        v = v.T                 \n",
    "        t = np.array(np.arange(1,row+1)).reshape(-1,1)  #This line generates a column vector t containing values from 1 to row, representing the row numbers.\n",
    "\n",
    "        v = np.hstack((v, t))                      #This line horizontally stacks v and t, resulting in a matrix where the first column contains the values of v and the second column contains the row numbers.\n",
    "        v_sort = v[v[:,0].argsort(),]                 #This line sorts v based on the values in the first column, resulting in v_sort.\n",
    "        v_sort_sel = v_sort[row-n:row, :]             #This line selects the last n rows from v_sort and assigns the result to v_sort_sel.\n",
    "        vv = v_sort_sel[v_sort_sel[:,1].argsort(),]   #This line sorts v_sort_sel based on the values in the second column, resulting in vv\n",
    "        #tt = numpy.array([vv[:,0]])                  #The subsequent code block handles the concatenation of vv[:, 0] (the first column of vv) with the previous iterations' results stored in xx\n",
    "        if i!=0:\n",
    "            if i==1:\n",
    "                pp = np.array([xx])\n",
    "                pp = pp.T\n",
    "            else:\n",
    "                pp = xx\n",
    "            pp2 = np.array([vv[:,0]])\n",
    "            pp2 = pp2.T\n",
    "            xx = np.hstack((pp, pp2))\n",
    "        else:\n",
    "            xx = np.concatenate((xx, vv[:,0]))\n",
    "    return xx                                         # xx is a matrix containing the selected energies for all the frames with size n x col\n",
    "\n",
    "\n",
    "def temp_vec_corr(x2, t_sigma):\n",
    "    from scipy.stats import norm\n",
    "    y = x2.shape\n",
    "    row = y[0]\n",
    "    col = y[1]\n",
    "    wn = norm.pdf(np.arange(1,col+1,1), (col+1)/2, t_sigma)              # pdf function with mean = (col+1)/2 and std = t_sigma as window\n",
    "    # NOTE: if we use continue to manipulate the variable x2, (the function argument), then it gets reflected back in\n",
    "    # in the parent function. (No idea why). So create a copy of x2 and work with that.\n",
    "    x3 = np.zeros((row,col))\n",
    "    for i in range(0,row,1):\n",
    "        x3[i,:] = np.multiply(x2[i,:],wn)                                # windowing the frame energies\n",
    "    s=0\n",
    "    for i in range(0,col-1,1):\n",
    "        for j in range(i+1,col,1):\n",
    "            s+= np.multiply(x3[:,i], x3[:,j])                             # computing the correlation between the consecutive frames \n",
    "    if col!=1:\n",
    "        s = np.sqrt(np.divide(s, (col-1)*col/2))\n",
    "    else:\n",
    "        s = x3                                                             \n",
    "    return s\n",
    "\n",
    "def temporal_corr(x, win, t_sigma):\n",
    "    hwin = (win-1)/2           # hwin is the half window size\n",
    "    yy = x.shape\n",
    "    row = yy[0]\n",
    "    col = yy[1]\n",
    "\n",
    "    row = int(row)\n",
    "    hwin = int(hwin)\n",
    "\n",
    "    x = np.array([np.concatenate((np.zeros((row,hwin)), x, np.zeros((row, hwin))), axis = 1)])              # zero padding the input matrix, hwin zeros on each sides of the columns\n",
    "    y = []\n",
    "    for i in range(hwin,col+hwin,1):\n",
    "        temp2 = x[0,:,i-hwin:i+hwin+1]\n",
    "        z = temp_vec_corr(temp2, t_sigma)\n",
    "        z = np.array([z]).T\n",
    "        if i==hwin:\n",
    "            y = np.concatenate((y, z[:,0]))\n",
    "        else:\n",
    "            if i==hwin+1:\n",
    "                y = np.array([y]).T\n",
    "            y = np.hstack((y, z))\n",
    "    return y\n",
    "\n",
    "def spectral_corr(x):\n",
    "    yy = x.shape\n",
    "    row = yy[0]\n",
    "    col = yy[1]\n",
    "\n",
    "    s = np.zeros((1, col))\n",
    "    for i in range(0, row-1, 1):\n",
    "        for j in range(i+1, row, 1):\n",
    "            s = s+np.multiply(x[i,:], x[j,:])\n",
    "\n",
    "    if row!=1:\n",
    "        s = np.sqrt(np.divide(s, (row*(row-1)/2)))\n",
    "    else:\n",
    "        s = x\n",
    "    return s\n",
    "\n",
    "def statFunctions_Syl(t):\n",
    "    from scipy.stats.mstats import gmean\n",
    "    if np.min(t)<0:\n",
    "        t = np.subtract(t,min(t[0]))\n",
    "        #out = []\n",
    "        #return out\n",
    "    out = np.array([np.median(t[0]), np.mean(t[0]), gmean(np.absolute(t[0])), np.max(t[0])-np.min(t[0]), np.std(t[0])])\n",
    "    out = np.array([out]).T\n",
    "    t = np.subtract(t,np.min(t[0]))\n",
    "    t = np.divide(t, np.sum(t[0]))\n",
    "    tempArr = np.array([np.arange(1,len(t[0])+1)])\n",
    "    temporalMean = np.sum(np.multiply(tempArr,t)[0])\n",
    "    temporalStd = np.sqrt(np.sum(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),2),t[0])))\n",
    "    temporalSkewness = np.sum(np.divide(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),3),t[0]),np.power(temporalStd,3)))\n",
    "    temporalKurthosis = np.sum(np.divide(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),4),t[0]),np.power(temporalStd,4)))\n",
    "    arr1 = np.array([np.array([temporalStd, temporalSkewness, temporalKurthosis])]).T\n",
    "    out = np.vstack((out,arr1))\n",
    "    return out\n",
    "\n",
    "def statFunctions_Vwl(t):\n",
    "    if np.min(t)<0:\n",
    "        t = np.subtract(t,min(t[0]))\n",
    "        #out = []\n",
    "        #eturn out\n",
    "    out = np.array([np.median(t[0]), np.mean(t[0]), np.max(t[0])-np.min(t[0]), np.std(t[0])])\n",
    "    out = np.array([out]).T\n",
    "    t = np.subtract(t,np.min(t[0]))\n",
    "    t = np.divide(t, np.sum(t[0]))\n",
    "    tempArr = np.array([np.arange(1,len(t[0])+1)])\n",
    "    temporalMean = np.sum(np.multiply(tempArr,t)[0])\n",
    "    temporalStd = np.sqrt(np.sum(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),2),t[0])))\n",
    "    temporalSkewness = np.sum(np.divide(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),3),t[0]),np.power(temporalStd,3)))\n",
    "    temporalKurthosis = np.sum(np.divide(np.multiply(np.power(np.subtract(np.array([np.arange(1,len(t[0])+1)]),temporalMean),4),t[0]),np.power(temporalStd,4)))\n",
    "    arr1 = np.array([np.array([temporalStd, temporalSkewness, temporalKurthosis])]).T\n",
    "    out = np.vstack((out,arr1))\n",
    "    return out\n",
    "\n",
    "def smooth(t_cor, swin, sigma):\n",
    "    from scipy.stats import norm\n",
    "    ft = norm.pdf(np.arange(1,swin+1), (swin+1)/2, sigma)\n",
    "    ft = np.array([ft])\n",
    "    t_cor = np.array([t_cor])\n",
    "    convRes = np.zeros((1, t_cor.shape[2]+ft.shape[1]-1))\n",
    "    convRes = np.convolve(t_cor[0,0,:], ft[0,:])\n",
    "    y = convRes[np.arange((swin+1)//2-1, len(convRes)-(swin-1)//2, 1)]\n",
    "    return y\n",
    "\n",
    "def get_labels(lab_list,fa,fileName):\n",
    "        L=[]; fb=fa; filenm=[];\n",
    "        \n",
    "        for num in range(0,len(lab_list)):\n",
    "            if str((lab_list[num][0].tolist())[0]) == str('P'):\n",
    "                L.append(1)\n",
    "                filenm.append(fileName)           \n",
    "            else:\n",
    "                L.append(0)\n",
    "                filenm.append(fileName)\n",
    "        fb = np.vstack((fa,L))\n",
    "#        fb = np.vstack((fb,np.asarray(filenm,object)))\n",
    "        return fb,filenm\n",
    "\n",
    "def get_labels_seq2seq(lab_list):\n",
    "        L=[];# filenm=[];\n",
    "        \n",
    "        for num in range(0,len(lab_list)):\n",
    "            if str((lab_list[num][0].tolist())[0]) == str('P'):\n",
    "                L.append(1)\n",
    "#                filenm.append(fileName)           \n",
    "            else:\n",
    "                L.append(0)\n",
    "                #filenm.append(fileName)\n",
    "        #fb = np.vstack((fa,L))\n",
    "#        fb = np.vstack((fb,np.asarray(filenm,object)))\n",
    "        return L\n",
    "    \n",
    "def vocoder_func(wavPath):\n",
    "\n",
    "    # FILTER DEFINITIONS\n",
    "\n",
    "    def butter_bandpass(lowcut, highcut, fs, order):\n",
    "        nyq = 0.5*fs\n",
    "        low = float(lowcut) / nyq\n",
    "        high = float(highcut) / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        return b, a\n",
    "\n",
    "    def butter_lowpass(lowcut, fs, order):\n",
    "        nyq = 0.5*fs\n",
    "        low = float(lowcut) / nyq\n",
    "        b ,a = butter(order, low, btype='lowpass')\n",
    "        return b, a\n",
    "\n",
    "    def butter_bandpass_filter(data, lowcut, highcut, fs, order):\n",
    "        b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    def butter_lowpass_filter(data, lowcut, fs, order):\n",
    "        b, a = butter_lowpass(lowcut, fs, order=order)\n",
    "        y = lfilter(b, a, data)\n",
    "        return y\n",
    "\n",
    "    # FUNCTION TO READ A .wav FILE MATLAB STYLE\n",
    "\n",
    "    def readWav(wavPath):\n",
    "        waveFile = wave.open(wavPath)\n",
    "        fs = waveFile.getframerate()\n",
    "        length = waveFile.getnframes()\n",
    "        data = []\n",
    "        for i in range(0, length):\n",
    "            waveData = waveFile.readframes(1)\n",
    "            data.append(struct.unpack(\"<h\", waveData))\n",
    "        waveFile.close()\n",
    "        data = np.array([data])\n",
    "        data = data.astype(float)/np.max(np.abs(data))\n",
    "        data = data[0]\n",
    "        return data, fs, length\n",
    "\n",
    "    # BUFFER FUNCTION AS DEFINED IN MATLAB\n",
    "\n",
    "    def buffer(x, n, p=0, opt=None):\n",
    "        import numpy\n",
    "        if p >= n:\n",
    "            raise ValueError('p ({}) must be less than n ({}).'.format(p,n))\n",
    "        cols = int(numpy.ceil(len(x)/float(n-p)))+1\n",
    "        if opt == 'nodelay':\n",
    "            cols += 1\n",
    "        elif opt != None:\n",
    "            raise SystemError('Only `None` (default initial condition) and '\n",
    "                              '`nodelay` (skip initial condition) have been '\n",
    "                              'implemented')\n",
    "        b = numpy.zeros((n, cols))\n",
    "        j = 0\n",
    "        for i in range(cols):\n",
    "            if i == 0 and opt == 'nodelay':\n",
    "                b[0:n,i] = x[0:n]\n",
    "                continue\n",
    "            elif i != 0 and p != 0:\n",
    "                b[:p, i] = b[-p:, i-1]\n",
    "            else:\n",
    "                b[:p, i] = 0\n",
    "            k = j + n - p\n",
    "            n_end = p+len(x[j:k])\n",
    "            b[p:n_end,i] = x[j:k,0]\n",
    "            j = k\n",
    "        return b\n",
    "\n",
    "    fltcF= np.array([240,360,480,600,720,840,1000,1150,1300,1450,1600,1800,2000,2200,2400,2700,3000,3300,3750])\n",
    "    fltBW= np.array([120,120,120,120,120,120,150,150,150,150,150,200,200,200,200,300,300,300,500])\n",
    "\n",
    "    fltFc= np.array([np.subtract(fltcF,np.divide(fltBW,2)),np.add(fltcF,np.divide(fltBW,2))])\n",
    "    fltLpFc= 50\n",
    "\n",
    "    sig, Fs, length = readWav(wavPath)\n",
    "    print(\"sig.shape: \", sig.shape)\n",
    "    print(\"Fs: \", Fs)\n",
    "\n",
    "    # Saving the audio in a txt file\n",
    "    xx = np.append(Fs,sig)                       # sig is the amplitude of the audio signal\n",
    "\n",
    "    nWndw = int(round(Fs*0.02))\n",
    "    print(\"nWndw is: \", nWndw)\n",
    "\n",
    "    nOverlap = int(round(Fs*0.01))\n",
    "    print(\"nOverlap is: \", nOverlap)\n",
    "\n",
    "    sig = 0.99*sig/max(abs(sig))                 # Normalizing the signal\n",
    "    \n",
    "    # Windowing first and filtering next\n",
    "    sigFrames= buffer(sig*32768,nWndw,nOverlap)          # sig Frames is a 2D array where each column represents an analysis frame \n",
    "    subBandEnergies= np.zeros([19,sigFrames.shape[1]])   # 2D array with 19 rows and number of columns equal to number of frames\n",
    "\n",
    "    for j in range(0,sigFrames.shape[1]): \n",
    "        currFrame = np.array([sigFrames[:,j]])                  # 1D array with the selected frame\n",
    "        for i in range(0,fltFc.shape[1]):\n",
    "            fltFrame = butter_bandpass_filter(currFrame[0], fltFc[0][i], fltFc[1][i], Fs, 2); fltFrame = fltFrame.T  # this line applies the bandpass filter to the current frame with fltFc[0][i] as lowcut and fltFc[1][i] as highcut\n",
    "            rectFrame = np.abs(fltFrame[0:nWndw])\n",
    "            lpFltFrame = butter_lowpass_filter(rectFrame, float(fltLpFc), Fs, 2)\n",
    "            currEnergy = lpFltFrame[nWndw-1]\n",
    "            if currEnergy < 1:\n",
    "                currEnergy = 0.5\n",
    "            subBandEnergies[i,j] = math.exp(2*math.log(currEnergy)/math.log(10))\n",
    "    subBandEnergies = np.concatenate((np.exp(0.5*np.ones((19,1))),subBandEnergies[:,0:-2]),axis=1).T\n",
    "\n",
    "    return Fs, subBandEnergies, xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'typical_FA_contextfeats'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanke\\Documents\\Sankeerthana\\Sankeerthana\\codes\\typical_FA_features.ipynb Cell 4\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mCreated on Mon Dec 12 10:51:41 2022\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m@author: iiit\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypical_FA_contextfeats\u001b[39;00m \u001b[39mimport\u001b[39;00m contextFeats\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'typical_FA_contextfeats'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Mon Dec 12 10:51:41 2022\n",
    "\n",
    "@author: iiit\n",
    "\"\"\"\n",
    "from typical_FA_contextfeats import contextFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISLE_SESS0006_BLOCKD01_01_sprt1.wav\n",
      "../data/fisher-2000_FA_GT_ESTphnTrans_estStress/lab/txt/phn/ISLE_SESS0006_BLOCKD01_01_sprt1.txt\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanke\\AppData\\Local\\Temp\\ipykernel_19844\\3414640566.py:45: UserWarning: loadtxt: input contained no data: \"<_io.TextIOWrapper name='C:\\\\Users\\\\sanke\\\\AppData\\\\Local\\\\Temp\\\\tmpy8uj1dy8' mode='r' encoding='cp1252'>\"\n",
      "  dataArray = np.loadtxt(fid, dtype={'names': ('a', 'b', 'c'), 'formats': ('f4', 'f4', 'S16')})\n",
      "C:\\Users\\sanke\\AppData\\Local\\Temp\\ipykernel_19844\\3414640566.py:61: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  index = np.argwhere(origPhones[0]=='sil')\n",
      "C:\\Users\\sanke\\AppData\\Local\\Temp\\ipykernel_19844\\3414640566.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  phones = phones[phones!='sil']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanke\\Documents\\Sankeerthana\\Sankeerthana\\codes\\typical_FA_features.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W0sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m phnCount\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W0sZmlsZQ%3D%3D?line=190'>191</a>\u001b[0m spurtSyl\u001b[39m=\u001b[39m [] \u001b[39m#spurtSylTimes= np.zeros((len(phnTimes),2))\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W0sZmlsZQ%3D%3D?line=192'>193</a>\u001b[0m syls_word \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(pathInds)))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W0sZmlsZQ%3D%3D?line=193'>194</a>\u001b[0m spurtWordTimes\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(pathInds),\u001b[39m2\u001b[39m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/sanke/Documents/Sankeerthana/Sankeerthana/codes/typical_FA_features.ipynb#W0sZmlsZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mfor\u001b[39;00m iterPath \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(pathInds)):\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "transDir= \"../data/\"\n",
    "dictDir= \"../\"\n",
    "transFile = \"ISLEtrans.txt\"\n",
    "dictName = \"nativeEnglishDict_gt100_manoj.syl\"\n",
    "models = ['fisher-2000_FA_GT_ESTphnTrans_estStress']#'libri-960_FA_GT_ESTphnTrans_estStress','wsj_FA_GT_ESTphnTrans_estStress','fisher-2000_FA_GT_ESTphnTrans_estStress','fisher-30_FA_GT_ESTphnTrans_estStress']\n",
    "#libri-30_FA_GT_ESTphnTrans_estStress\n",
    "model_FA = ['FA_htkCorrectedLabWithFullAudio']\n",
    "labels_mis_count=[]\n",
    "for mod in range(0,len(models)):\n",
    "    Features = []\n",
    "    phonecountError=1\n",
    "    filenotExist=1\n",
    "    prevSuccessError=1\n",
    "    done=0\n",
    "    label_mismatch=0\n",
    "    model = models[mod]\n",
    "    filepath = '../data/'+model+'/lab/txt/phn/'\n",
    "    files = os.listdir('../data/GER/train/') \n",
    "    print(files[0])\n",
    "    \n",
    "    wavPath = '../data/GER/train/'\n",
    "    \n",
    "    stressLabelspath = '../data/'+model_FA[0]+'/lab/mat/sylStress/'\n",
    "    #VOWEL LIST\n",
    "    vowelList= ['aa','ae','ah','ao','aw','ay','eh','er','ey','ih','iy','ow','oy','uh','uw']\n",
    "    \n",
    "    for fileN in range(0,len(files)): #len(files)\n",
    "        \n",
    "        is_looping = True\n",
    "        wavFile =wavPath+files[fileN]#files[fileN]\n",
    "        fileName = files[fileN]#files[fileN]\n",
    "        phnFile = filepath+fileName[0:-4]+'.txt'\n",
    "        print(phnFile)\n",
    "    \n",
    "        if os.path.exists(stressLabelspath + fileName[:-4] + '.mat'):\n",
    "\n",
    "            with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp_file:\n",
    "                temp_filename = tmp_file.name\n",
    "                \n",
    "                # loading of data\n",
    "                subprocess.call([\"type \" + phnFile + \" | tr \\\"\\t\\\" \\\" \\\" > \" + temp_filename], shell=True)\n",
    "\n",
    "                try:\n",
    "                    with open(temp_filename, 'r') as fid:\n",
    "                        dataArray = np.loadtxt(fid, dtype={'names': ('a', 'b', 'c'), 'formats': ('f4', 'f4', 'S16')})\n",
    "\n",
    "                except FileNotFoundError:\n",
    "                    print('File does not exist')\n",
    "                    filenotExist += 1\n",
    "                    os.remove(temp_filename)  # Clean up temporary file\n",
    "\n",
    "            os.remove(temp_filename)  # Clean up temporary file after processing\n",
    "    \n",
    "            phnTimes1 = [row[0] for row in dataArray];phnTimes1 = np.array([phnTimes1]).T\n",
    "            phnTimes2 = [row[1] for row in dataArray];phnTimes2 = np.array([phnTimes2]).T\n",
    "            phnTimes = np.hstack((phnTimes1, phnTimes2))\n",
    "            phones = [row[2] for row in dataArray];phones = np.array([phones])\n",
    "            for kk in range (0,len(phones[0])):\n",
    "                phones[0][kk] = phones[0][kk].lower()      # Made them lowercase since the syl dictionary is in lowercase\n",
    "            origPhones = phones\n",
    "            index = np.argwhere(origPhones[0]=='sil')\n",
    "            phones = phones[phones!='sil']\n",
    "            phones = np.array([phones])\n",
    "        \n",
    "            #Getting vowel data\n",
    "            vowelStartTime = []; vowelEndTime = []; vowel = []\n",
    "            for kk in range(0,len(dataArray)):\n",
    "                if dataArray[kk][2].lower() in vowelList:\n",
    "                    vowelStartTime.append(dataArray[kk][0]); vowelEndTime.append(dataArray[kk][1]); vowel.append(dataArray[kk][2].lower())\n",
    "            vowelStartTime = np.array([vowelStartTime])\n",
    "            vowelEndTime = np.array([vowelEndTime])\n",
    "            vowel = np.array([vowel])\n",
    "\n",
    "            print(vowel)\n",
    "        \n",
    "            #sylPhnTimes = phnTimes[index][0]\n",
    "            phnTimes2 = np.delete(phnTimes2, index, axis=0)\n",
    "            phnTimes = np.delete(phnTimes, index, axis=0)\n",
    "\n",
    "            print(phnTimes)\n",
    "\n",
    "            trans_path = transDir + \"ISLEtrans.txt\"\n",
    "\n",
    "            # Read the contents of the transcript file\n",
    "            with open(trans_path, 'r') as trans_file:\n",
    "                trans_contents = trans_file.read()\n",
    "\n",
    "            # Extract the lines containing the specified filename from the transcript\n",
    "            lines = [line for line in trans_contents.split('\\n') if fileName in line]\n",
    "\n",
    "            # Extract the words from the lines and clean them up\n",
    "            words = []\n",
    "            for line in lines:\n",
    "                _, word_list = line.split(' ', 1)\n",
    "                words.extend(re.findall(r'\\b\\w+\\b', word_list))\n",
    "            words = [word.lower() for word in words]\n",
    "\n",
    "            print(words)\n",
    "\n",
    "\n",
    "            flag = 0\n",
    "            word_syls = []\n",
    "            for iterWord in range(0,len(words),1):\n",
    "                subprocess.call([\"cat \"+dictDir+dictName+\" | sed -e \\\"s/^/+/g\\\" | grep \\\"+\"+words[iterWord]+\" \\\" | cut -d\\\"=\\\" -f2 > /tmp/tmp.txt\"], shell = True)\n",
    "                with open(\"/tmp/tmp.txt\", 'r') as fid: \n",
    "                    tempArr = [tempArr.rstrip('\\n') for tempArr in fid]\n",
    "                word_syls.append(tempArr)\n",
    "                sylSuccess_flag = 0\n",
    "            k=0\n",
    "        \n",
    "            for i in range(0,len(word_syls)):\n",
    "                for j in range(0,len(word_syls[i])):\n",
    "                    if word_syls[i][j][0]== ' ':\n",
    "                        word_syls[i][j] = word_syls[i][j].replace(' ', '', 1)\n",
    "\n",
    "            print(word_syls)\n",
    "        \n",
    "            # Finding the syllables path that matches phone transcriptions for each file.\n",
    "            newSuccessInds_all = []\n",
    "            newSuccessInds_all2 = []\n",
    "            prevSuccessInds_all = []\n",
    "            prevSuccessInds_all.append(0)\n",
    "\n",
    "            for iterWord in range(0,len(words)):\n",
    "                currWordSyls = word_syls[iterWord]\n",
    "                countSuccess = 1\n",
    "                for iterPrev in range(0,len(prevSuccessInds_all)):\n",
    "                    prevWordSyls = \"\"\n",
    "                    if prevSuccessInds_all[iterPrev] == 0:\n",
    "                        currPrevSylInds = []\n",
    "                    else:\n",
    "                        currPrevSylInds=prevSuccessInds_all[iterPrev]\n",
    "                        for iterPrevSyls in range(0,len(currPrevSylInds)):\n",
    "                            temp = word_syls[iterPrevSyls]\n",
    "                            prevWordSyls = prevWordSyls+temp[currPrevSylInds[iterPrevSyls]]+\" \"\n",
    "\n",
    "                    for iterCurr in range(0,len(currWordSyls)):\n",
    "                        \n",
    "                        currTestWordSyls = prevWordSyls+currWordSyls[iterCurr]\n",
    "                        temp2 = currTestWordSyls.replace(' . ',' ')\n",
    "                        inds = [m.start() for m in re.finditer(' ',temp2)]\n",
    "                        if len(inds) == 0:\n",
    "                            inds = [len(temp2)]\n",
    "                        count = 1\n",
    "                        temp = []\n",
    "                        for iterTemp in range(0,len(inds),1):\n",
    "                            if iterTemp == 0:\n",
    "                                temp1 = temp2[0:inds[iterTemp]]\n",
    "                            else:\n",
    "                                temp1 = temp2[inds[iterTemp-1]+1:inds[iterTemp]]\n",
    "                            if not((np.unique(temp1) == ' ').any() or (len(temp1)==0)):\n",
    "                                temp.append(temp1)\n",
    "                                count = count+1\n",
    "                        if iterTemp==len(inds)-1 and len(inds)<len(currTestWordSyls):\n",
    "                            temp1 = temp2[inds[iterTemp]+1:len(temp2)]\n",
    "                            if not((len(temp1)==0) or (np.unique(temp1) == ' ').any()):\n",
    "                                temp.append(temp1)\n",
    "                                count = count+1\n",
    "                        if iterWord+1==len(words):\n",
    "                            currPhones = phones[0,0:len(phones[0])]\n",
    "        \n",
    "                        else:\n",
    "                            currPhones = phones[0][0:len(temp)]\n",
    "                        flag = 1\n",
    "                        for iterFlag in range(0,len(currPhones),1):\n",
    "                            if len(currPhones)!=len(temp):\n",
    "                                flag = 0\n",
    "                            else:\n",
    "                                if currPhones[iterFlag]!=temp[iterFlag]:\n",
    "                                    flag = 0\n",
    "                        if flag==1:\n",
    "                            if not currPrevSylInds==[]:\n",
    "                                for i in range(0,len(currPrevSylInds)):\n",
    "        #                            print('line 122::::::yes')\n",
    "                                    newSuccessInds_all.append(currPrevSylInds[i])\n",
    "                            newSuccessInds_all.append(iterCurr)\n",
    "                            newSuccessInds_all2.append(newSuccessInds_all)\n",
    "                            newSuccessInds_all = []\n",
    "                            countSuccess = countSuccess+1\n",
    "                prevSuccessInds_all = newSuccessInds_all2\n",
    "                newSuccessInds_all2 = []\n",
    "        \n",
    "            # Compute syllable and word times\n",
    "            if len(prevSuccessInds_all) != 1:\n",
    "                prevSuccessError = prevSuccessError+1\n",
    "                continue\n",
    "            else:\n",
    "                pathInds= prevSuccessInds_all[0]\n",
    "                sylCount= 1\n",
    "                phnCount= 1\n",
    "                spurtSyl= [] #spurtSylTimes= np.zeros((len(phnTimes),2))\n",
    "        \n",
    "                syls_word = np.zeros((1,len(pathInds)))\n",
    "                spurtWordTimes= np.zeros((len(pathInds),2))\n",
    "\n",
    "                for iterPath in range(0,len(pathInds)):\n",
    "                    currWord = words[iterPath]\n",
    "                    currWordSyls = word_syls[iterPath]\n",
    "                    currSyl = currWordSyls[pathInds[iterPath]]\n",
    "                    currSyl= currSyl.replace(' . ','.')\n",
    "                    inds = [m.start() for m in re.finditer('\\.',currSyl)]\n",
    "                    if len(inds) == 0:\n",
    "                        inds = [len(currSyl)]\n",
    "                    count = 0\n",
    "                    for iterTemp in range(0,len(inds)):\n",
    "                        if iterTemp == 0:\n",
    "                            temp1 = currSyl[0:inds[iterTemp]]\n",
    "                        else:\n",
    "                            temp1 = currSyl[inds[iterTemp-1]+1:inds[iterTemp]]\n",
    "                        if not (temp1==' ' or len(temp1) == 0):\n",
    "                            spurtSyl.append(temp1)\n",
    "                            sylCount = sylCount+1\n",
    "                            count = count+1\n",
    "                    if iterTemp is len(inds)-1 and len(inds)<len(currTestWordSyls):\n",
    "                        temp1 = currSyl[inds[iterTemp]+1:len(currSyl)]\n",
    "                        if not (temp1==' ' or len(temp1) == 0):\n",
    "                            spurtSyl.append(temp1)\n",
    "                            sylCount = sylCount+1\n",
    "                            count = count+1\n",
    "                    syls_word[0][iterPath] = count\n",
    "        \n",
    "                spurtSylTimes = np.zeros((len(spurtSyl),2))\n",
    "        \n",
    "                for iterSyl in range(0,len(spurtSyl)):\n",
    "                    temp2 = spurtSyl[iterSyl]\n",
    "                    inds = [m.start() for m in re.finditer(' ',temp2)]\n",
    "                    if len(inds) == 0:\n",
    "                        inds = [len(temp2)]\n",
    "                    count = 1\n",
    "                    temp = []\n",
    "                    for iterTemp in range(0,len(inds)):\n",
    "                        if iterTemp == 0:\n",
    "                            temp1 = temp2[0:inds[iterTemp]]\n",
    "                        else:\n",
    "                            temp1 = temp2[inds[iterTemp-1]+1:inds[iterTemp]]\n",
    "                        if not(temp1 == ' ' or len(temp1) == 0):\n",
    "                            temp.append(temp1)\n",
    "                            count = count+1\n",
    "                    if iterTemp==len(inds)-1 and len(inds)<len(currTestWordSyls):\n",
    "                        temp1 = temp2[inds[iterTemp]+1:len(temp2)]\n",
    "                        if not (temp1 == ' ' or len(temp1)==0):\n",
    "                            temp.append(temp1)\n",
    "                            count = count+1\n",
    "        \n",
    "                    nPhns_syl = len(temp)\n",
    "                    spurtSylTimes[iterSyl,0] = phnTimes[phnCount-1,0]\n",
    "                    phnCount = phnCount + nPhns_syl\n",
    "                    spurtSylTimes[iterSyl,1] = phnTimes[phnCount-1-1,1]\n",
    "                length_spurtSylTimes = iterSyl+1\n",
    "                if len(phones[0]) != (phnCount-1):\n",
    "                    phonecountError = phonecountError+1\n",
    "        \n",
    "                sylIdx = 1\n",
    "                for iterWordTimes in range(0,len(syls_word[0])):\n",
    "                    spurtWordTimes[iterWordTimes,0] = spurtSylTimes[sylIdx-1,0]\n",
    "                    sylIdx = sylIdx + syls_word[0][iterWordTimes].astype(int)\n",
    "                    spurtWordTimes[iterWordTimes,1] = spurtSylTimes[sylIdx-1-1,1]\n",
    "                length_spurtWordTimes = iterWordTimes+1\n",
    "        \n",
    "        \n",
    "        # Create syllable files done    ########################################################################################\n",
    "                                        ########################################################################################\n",
    "        # Compute features              ########################################################################################\n",
    "            twin = 5\n",
    "            t_sigma = 1.4\n",
    "            swin = 7\n",
    "            s_sigma = 1.5\n",
    "            mwin = 13\n",
    "            max_threshold = 25\n",
    "            \n",
    "            vwlSB_num= 4\n",
    "            vowelSB= [1,2,4,5,6,7,8,13,14,15,16,17]\n",
    "            sylSB_num= 5\n",
    "            sylSB= [1,2,3,4,5,6,13,14,15,16,17,18]\n",
    "            \n",
    "            startWordFrame_all = []\n",
    "            spurtStartFrame_all = []\n",
    "            spurtEndFrame_all=[]\n",
    "            vowelStartFrame_all = []\n",
    "            vowelEndFrame_all = []\n",
    "            eng_full_all = []\n",
    "            spurtStress_all = []\n",
    "            \n",
    "            # Execute the vocoder [MODIFICATION]: Get the audio file back so that it can be stored in a text file for C code.\n",
    "            Fs, eng_full, xx = vocoder_func(wavFile)\n",
    "            #eng_full = np.loadtxt('./ISLE_SESS0003_BLOCKD01_11_sprt1.e19' , delimiter=',')\n",
    "            eng_full = eng_full.conj().transpose()\n",
    "            \n",
    "            \n",
    "            # Processing word boundary file\n",
    "            # FILE READ DELETED HERE\n",
    "            a = spurtWordTimes\n",
    "            b = words\n",
    "            if(len(a) is not len(b)):\n",
    "                continue\n",
    "            wordData = np.hstack((a, np.array([b], dtype='S32').T))\n",
    "            startWordTime = [row[0] for row in wordData]  # Extract first coloumn of wordData\n",
    "            endWordTime = [row[1] for row in wordData]\n",
    "            startWordFrame = np.round((np.subtract(np.array(startWordTime, dtype='float'), spurtSylTimes[0][0].astype(float))*100))\n",
    "            endWordFrame = np.round((np.subtract(np.array(endWordTime, dtype='float'), spurtSylTimes[0][0].astype(float))*100) + 1)\n",
    "            startWordFrame = np.append(startWordFrame,endWordFrame[-1])\n",
    "            \n",
    "            # Processing of stress and syllable boundary file\n",
    "            spurtSylTime = spurtSylTimes\n",
    "            spurtStartTime = spurtSylTime[:, 0]\n",
    "            spurtEndTime = spurtSylTime[:, 1]\n",
    "            spurtStartFrame = np.round((spurtStartTime - spurtStartTime[0]) * 100)\n",
    "            spurtEndFrame = np.round((spurtEndTime - spurtStartTime[0]) * 100)\n",
    "            \n",
    "            # Processing of Vowel boundary file\n",
    "            vowelStartFrame = np.round(vowelStartTime*100 - spurtStartTime[0] * 100)\n",
    "            vowelEndFrame = np.round(vowelEndTime*100 - spurtStartTime[0] * 100)\n",
    "            \n",
    "            # TCSSBC computation\n",
    "            if len(sylSB) > sylSB_num:\n",
    "                eng = spectral_selection(eng_full[np.subtract(sylSB, 1), :], sylSB_num)\n",
    "            else:\n",
    "                eng = eng_full[sylSB, :]\n",
    "            t_cor = temporal_corr(eng, twin, t_sigma)\n",
    "            s_cor = spectral_corr(t_cor)\n",
    "            sylTCSSBC = smooth(s_cor, swin, s_sigma)\n",
    "            sylTCSSBC = np.array([sylTCSSBC])\n",
    "            \n",
    "            # Modify TCSSBC contour by clipping from the syllable start\n",
    "            start_idx = np.round(spurtStartTime[0]*100).astype(int)\n",
    "            sylTCSSBC = np.array([sylTCSSBC[0][start_idx:-1]])\n",
    "            \n",
    "            sylTCSSBC = np.divide(sylTCSSBC, max(sylTCSSBC[0]))\n",
    "            \n",
    "            if len(vowelSB) > vwlSB_num:\n",
    "                eng = spectral_selection(eng_full[np.subtract(vowelSB, 1), :], vwlSB_num)\n",
    "            else:\n",
    "                eng = eng_full[vowelSB, :]\n",
    "            t_cor = temporal_corr(eng, twin, t_sigma)\n",
    "            s_cor = spectral_corr(t_cor)\n",
    "            vwlTCSSBC = smooth(s_cor, swin, s_sigma)\n",
    "            \n",
    "            vwlTCSSBC = np.array([vwlTCSSBC])\n",
    "            \n",
    "            # Modify TCSSBC contour by clipping from the vowel start\n",
    "            start_idx = np.round(vowelStartTime[0][0]*100).astype(int)\n",
    "            vwlTCSSBC = np.array([vwlTCSSBC[0][start_idx:-1]])\n",
    "            \n",
    "            vwlTCSSBC = np.divide(vwlTCSSBC, max(vwlTCSSBC[0]))\n",
    "            \n",
    "            # Compute silence statistics\n",
    "            # Preprocessing of the data\n",
    "            word_duration = np.zeros((1, len(startWordFrame) - 1))\n",
    "            word_Sylsum = np.zeros((1, len(startWordFrame) - 1))\n",
    "            word_Vwlsum = np.zeros((1, len(startWordFrame) - 1))\n",
    "            \n",
    "            for j in range(0, len(startWordFrame) - 1):\n",
    "                temp_start = startWordFrame[j].astype(int)\n",
    "                temp_end = startWordFrame[j + 1].astype(int) - 1\n",
    "                #jhansi\n",
    "                if (temp_end >= sylTCSSBC.shape[1]):\n",
    "                    temp_end1 = sylTCSSBC.shape[1]-1\n",
    "                    sylTCSSBC[0, np.arange(temp_start, temp_end1)] = medfilt(sylTCSSBC[0, np.arange(temp_start, temp_end1)], 3)\n",
    "                    sylTCSSBC[0, temp_start] = sylTCSSBC[0, temp_start+1]\n",
    "                    sylTCSSBC[0, temp_end1] = sylTCSSBC[0, temp_end1 - 1]\n",
    "                    tempArr = sylTCSSBC[0, np.arange(temp_start, temp_end1)]\n",
    "                    word_Sylsum[0, j] = tempArr.sum(axis=0)\n",
    "                else:\n",
    "                    sylTCSSBC[0, np.arange(temp_start, temp_end)] = medfilt(sylTCSSBC[0, np.arange(temp_start, temp_end)], 3)\n",
    "                    sylTCSSBC[0, temp_start] = sylTCSSBC[0, temp_start+1]\n",
    "                    sylTCSSBC[0, temp_end] = sylTCSSBC[0, temp_end - 1]\n",
    "                    tempArr = sylTCSSBC[0, np.arange(temp_start, temp_end)]\n",
    "                    word_Sylsum[0, j] = tempArr.sum(axis=0)\n",
    "                if (temp_end >= vwlTCSSBC.shape[1]):\n",
    "                    temp_end = vwlTCSSBC.shape[1]-1\n",
    "            #    temp_end = np.min([temp_end,len(vwlTCSSBC)])\n",
    "                vwlTCSSBC[0, np.arange(temp_start, temp_end)] = medfilt(vwlTCSSBC[0, np.arange(temp_start, temp_end)], 3)\n",
    "                vwlTCSSBC[0, temp_start] = vwlTCSSBC[0, temp_start+1]\n",
    "                vwlTCSSBC[0, temp_end] = vwlTCSSBC[0, temp_end - 1]\n",
    "            \n",
    "                word_duration[0, j] = temp_end - temp_start + 1\n",
    "    \n",
    "                tempArr = vwlTCSSBC[0, np.arange(temp_start, temp_end)]\n",
    "                word_Vwlsum[0, j] = tempArr.sum(axis=0)\n",
    "            sylTCSSBC[np.isnan(sylTCSSBC)] = 0\n",
    "            vwlTCSSBC[np.isnan(vwlTCSSBC)] = 0\n",
    "            tempOut = np.array([[]])\n",
    "            \n",
    "            wordIndication = []\n",
    "            peakVals = []\n",
    "            avgVals = []\n",
    "            \n",
    "            # Generating the features\n",
    "            for j in range(0, len(spurtSyl), 1):\n",
    "                inds = (startWordFrame <= spurtStartFrame[j]).nonzero()\n",
    "                word_ind = inds[0][-1]\n",
    "                wordIndication.append(word_ind)\n",
    "        #       print([0, np.arange(spurtStartFrame[j], spurtEndFrame[j]-1, 1).astype(int)])\n",
    "                currFtr1SylSeg = sylTCSSBC[0, np.arange(spurtStartFrame[j], spurtEndFrame[j]-1, 1).astype(int)]\n",
    "                currFtr1SylSeg = np.array([currFtr1SylSeg])\n",
    "                temp = np.multiply(currFtr1SylSeg, len(currFtr1SylSeg[0]) / word_duration[0, word_ind])\n",
    "                # arrResampled = np.array([librosa.resample(temp[0], float(30) / len(temp[0]), 'sinc_best')])\n",
    "                arrResampled = np.array([librosa.resample(temp[0], Fs, Fs*float(30) / len(temp[0]), 'sinc_best')])       ##change\n",
    "                F_new = Fs*float(30) / len(temp[0])\n",
    "                \n",
    "                #To be put in the output file\n",
    "                peakVals.append(np.amax(arrResampled))\n",
    "                avgVals.append(np.average(arrResampled))\n",
    "            \n",
    "                currSylFtrs = statFunctions_Syl(arrResampled)\n",
    "                arr1 = np.array([np.array([np.sum(currFtr1SylSeg) / word_Sylsum[0, word_ind]])]).T\n",
    "                currSylFtrs = np.vstack((currSylFtrs, arr1))\n",
    "                ##########jhansi\n",
    "                if (j>= vowelEndFrame.shape[1]):\n",
    "                    break\n",
    "                if (vowelEndFrame [0,j] >= vwlTCSSBC.shape[1]):\n",
    "                    vowelEndFrame[0,j] = vwlTCSSBC.shape[1]-1\n",
    "            \n",
    "                currFtr1VowelSeg = vwlTCSSBC[0, np.arange(vowelStartFrame[0, j], vowelEndFrame[0, j]-1, 1).astype(int)]\n",
    "                currFtr1VowelSeg = np.array([currFtr1VowelSeg])\n",
    "                temp = np.multiply(currFtr1VowelSeg, len(currFtr1VowelSeg[0]) / word_duration[0, word_ind])\n",
    "                if (len(temp[0])==0):\n",
    "                    break\n",
    "                    \n",
    "                #arrResampled = np.array([scikits.samplerate.resample(temp[0], float(20) / len(temp[0]), 'sinc_best')])\n",
    "                arrResampled = np.array([librosa.resample(temp[0], F_new, F_new*float(20) / len(temp[0]), 'sinc_best')])\n",
    "                currVowelFtrs = statFunctions_Vwl(arrResampled)\n",
    "                arr1 = np.array([np.array([np.sum(currFtr1VowelSeg) / word_Sylsum[0, word_ind]])]).T\n",
    "                currVowelFtrs = np.vstack((currVowelFtrs, arr1))\n",
    "                if j == 0:\n",
    "                    tempOut = np.vstack((currSylFtrs, currVowelFtrs, len(currFtr1VowelSeg[0]), len(currFtr1SylSeg[0])))\n",
    "                else:\n",
    "                    tempOut = np.hstack((tempOut, np.vstack((currSylFtrs, currVowelFtrs,len(currFtr1VowelSeg[0]), len(currFtr1SylSeg[0])))))\n",
    "            if (len(temp[0])==0):\n",
    "                   continue\n",
    "            sylDurations = spurtEndTime - spurtStartTime\n",
    "            \n",
    "            ftrs = tempOut\n",
    "            \n",
    "            wordLabls = np.unique(wordIndication)\n",
    "            for iterWrd in range(0, len(wordLabls)):\n",
    "                inds = [i for i, x in enumerate(wordIndication) if x == wordLabls[iterWrd]] #doing argwhere(wordIndication==wordLabls[iterWrd]\n",
    "                if len(inds)>1 :\n",
    "                    ftrs[-1, inds] = ftrs[-1, inds] / sum(ftrs[-1, inds])\n",
    "                    ftrs[-2, inds] = ftrs[-2, inds] / sum(ftrs[-2, inds])\n",
    "            end=1\n",
    "            print(ftrs.shape)\n",
    "            fa = ftrs\n",
    "            \n",
    "            mat = scipy.io.loadmat(stressLabelspath+fileName[0:-4]+'.mat')\n",
    "            lab = mat['spurtStress']\n",
    "            lab_list = lab.tolist()\n",
    "            if (fa.shape[1] != len(lab_list)):\n",
    "                label_mismatch = label_mismatch+1\n",
    "    #            is_looping = False\n",
    "                continue\n",
    "            else:\n",
    "                fb,filenm = get_labels(lab_list,fa,fileName)\n",
    "                feats = fb #features ,last row:labels\n",
    "                w=[]#polysyl_feat=[];\n",
    "                for w_l in range(len(words)):\n",
    "            #        cou = 0\n",
    "                    w_st = spurtWordTimes[w_l][0]\n",
    "                    w_ed = spurtWordTimes[w_l][1]\n",
    "\n",
    "                    for s_l in range(len(w),len(spurtSyl)):\n",
    "                        sy_st = spurtSylTimes[s_l][0]\n",
    "                        sy_ed = spurtSylTimes[s_l][1]\n",
    "\n",
    "                        if (sy_ed <= w_ed):\n",
    "                            w.append(w_l+1)\n",
    "    #                        w.append('W'+str(w_l+1))\n",
    "            #                cou=cou+1\n",
    "                        else:\n",
    "                            break\n",
    "                if (len(w)>np.shape(feats)[1]):\n",
    "                    continue\n",
    "                feats = np.vstack((feats,w))#features ,last row:labels, word labels\n",
    "                AF_inform = filenm\n",
    "                CF_feats,CF_inform = contextFeats(spurtSyl,spurtSylTimes,spurtWordTimes,vowel)\n",
    "                if fileN == 0:#411 or fileN ==412:\n",
    "                    AF = feats\n",
    "                    AF_info = AF_inform\n",
    "                    CF = CF_feats\n",
    "                    CF_info =CF_inform                \n",
    "                else:\n",
    "                    AF = np.hstack((AF,feats)) \n",
    "                    AF_info = np.hstack((AF_info,AF_inform))\n",
    "                    CF = np.hstack((CF,CF_feats))\n",
    "                    CF_info = np.hstack((CF_info,CF_inform))\n",
    "                    done=done+1\n",
    "                    print('Done:::file number ' + str(done) + '  out of ' + str(len(files)))\n",
    "          \n",
    "    labels_mis_count.append(label_mismatch)\n",
    "    # scipy.io.savemat('/home/iiit/Desktop/Jhansi/Stress detection/Codes_jhansi/features/GER_train_'+model+'.mat', {'AF': AF,'CF': CF,'CF_info': CF_info,'AF_info': AF_info})\n",
    "    print(AF,CF,CF_info,AF_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
